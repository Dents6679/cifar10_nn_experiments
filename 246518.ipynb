{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkCHccyuG_Kg"
      },
      "source": [
        "# Assignment overview <ignore>\n",
        "The overarching goal of this assignment is to produce a research report in which you implement, analyse, and discuss various Neural Network techniques. You will be guided through the process of producing this report, which will provide you with experience in report writing that will be useful in any research project you might be involved in later in life.\n",
        "\n",
        "All of your report, including code and Markdown/text, ***must*** be written up in ***this*** notebook. This is not typical for research, but is solely for the purpose of this assignment. Please make sure you change the title of this file so that XXXXXX is replaced by your candidate number. You can use code cells to write code to implement, train, test, and analyse your NNs, as well as to generate figures to plot data and the results of your experiments. You can use Markdown/text cells to describe and discuss the modelling choices you make, the methods you use, and the experiments you conduct. So that we can mark your reports with greater consistency, please ***do not***:\n",
        "\n",
        "* rearrange the sequence of cells in this notebook.\n",
        "* delete any cells, including the ones explaining what you need to do.\n",
        "\n",
        "If you want to add more code cells, for example to help organise the figures you want to show, then please add them directly after the code cells that have already been provided. \n",
        "\n",
        "Please provide verbose comments throughout your code so that it is easy for us to interpret what you are attempting to achieve with your code. Long comments are useful at the beginning of a block of code. Short comments, e.g. to explain the purpose of a new variable, or one of several steps in some analyses, are useful on every few lines of code, if not on every line. Please do not use the code cells for writing extensive sentences/paragraphs that should instead be in the Markdown/text cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAAMLJvMBOnn"
      },
      "source": [
        "# Abstract/Introduction (instructions) - 15 MARKS <ignore>\n",
        "Use the next Markdown/text cell to write a short introduction to your report. This should include:\n",
        "* a brief description of the topic (image classification) and of the dataset being used (CIFAR10 dataset). (2 MARKS)\n",
        "* a brief description of how the CIFAR10 dataset has aided the development of neural network techniques, with examples. (3 MARKS)\n",
        "* a descriptive overview of what the goal of your report is, including what you investigated. (5 MARKS)\n",
        "* a summary of your major findings. (3 MARKS)\n",
        "* two or more relevant references. (2 MARKS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjQqL_Xb5cH1"
      },
      "source": [
        "*Enter your abstract/introduction here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5aTZVqp5uVv"
      },
      "source": [
        "# Methodology (instructions) - 55 MARKS <ignore>\n",
        "Use the next cells in this Methodology section to describe and demonstrate the details of what you did, in practice, for your research. Cite at least two academic papers that support your model choices. The overarching prinicple of writing the Methodology is to ***provide sufficient details for someone to replicate your model and to reproduce your results, without having to resort to your code***. You must include at least these components in the Methodology:\n",
        "* Data - Decribe the dataset, including how it is divided into training, validation, and test sets. Describe any pre-processing you perform on the data, and explain any advantages or disadvantages to your choice of pre-processing. \n",
        "* Architecture - Describe the architecture of your model, including all relevant hyperparameters. The architecture must include 3 convolutional layers followed by two fully connected layers. Include a figure with labels to illustrate the architecture.\n",
        "* Loss function - Describe the loss function(s) you are using, and explain any advantages or disadvantages there are with respect to the classification task.\n",
        "* Optimiser - Describe the optimiser(s) you are using, including its hyperparameters, and explain any advantages or disadvantages there are to using that optimser.\n",
        "* Experiments - Describe how you conducted each experiment, including any changes made to the baseline model that has already been described in the other Methodology sections. Explain the methods used for training the model and for assessing its performance on validation/test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ygcFzZZPRgB"
      },
      "source": [
        "## Data (7 MARKS) <ignore>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Describe the dataset and any pre-processing here*\n",
        "\n",
        "SD 1 MEAN 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW5bfoqFlAkI"
      },
      "source": [
        "## Architecture (17 MARKS) <ignore>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Describe the architecture here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og6OEUtIPT-P"
      },
      "source": [
        "## Loss function (3 MARKS) <ignore>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Describe the loss function here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh2Zgcj9PXAl"
      },
      "source": [
        "## Optimser (4 MARKS) <ignore>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Describe the optimiser here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J8SM1rMyReN"
      },
      "source": [
        "## Experiments <ignore>\n",
        "### Experiment 1 (8 MARKS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Describe how you went about conducting experiment 1 here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 2 (8 MARKS) <ignore>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Describe how you went about conducting experiment 2 here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 3 (8 MARKS) <ignore>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Describe how you went about conducting experiment 3 here*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "############################################\n",
        "### Code for building the baseline model ###\n",
        "############################################\n",
        "\n",
        "###\n",
        "# Collecting imports and loading dataset.\n",
        "###\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Fetching one sample batch from test data.\n"
          ]
        }
      ],
      "source": [
        "###\n",
        "# Load and Normalise Dataset into batches\n",
        "###\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "\n",
        "# Normalisation dict fn thing, taken from Lab 6's code to normalise CIFAR-10 dataset to mean 0, SD 1.\n",
        "transform = {\n",
        "    'train':transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "# Batch size to use in dataloaders\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "# Fetch training dataset and normalise it.\n",
        "full_train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform['train'])\n",
        "\n",
        "# Don't create train loader here as dataset needs to be split in differnet ways for later experiemnts\n",
        "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "# Create Testing Dataset\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform['test'])\n",
        "# Create Testing dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# fetch a batch of images and labels for testing (not the NN kind, the mess about to see if things are working kind)\n",
        "print(\"Fetching one sample batch from test data.\")\n",
        "dataiter = iter(test_loader)\n",
        "sample_images, sample_labels = next(dataiter)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Classes\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "# Create class to ID mapping\n",
        "id2classes = {idx:clss for idx, clss in enumerate(classes)}\n",
        "\n",
        "# Create ID to class mapping\n",
        "classes2id = {clss:idx for idx,clss in id2classes.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "###\n",
        "# Handy functions for later\n",
        "###\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"\n",
        "    Shows an image from a Tensor representation.\n",
        "    Taken from Lab 6 work\n",
        "    \"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "imshow(sample_images[1], id2classes[int(sample_labels[1])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "# Create the Network itsself\n",
        "###\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BaselineNetwork(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "            Creates the network.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Create first cnn layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=0) \n",
        "        # Create second cnn layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        # Create third cnn layer\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=48, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Create pooling layer used throughout\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) # Pooling layer to downsample representations.\n",
        "\n",
        "        # Create first linear layer\n",
        "        self.fc1 = nn.Linear(in_features=48*3*3, out_features=160)\n",
        "        # Create second linear layer\n",
        "        self.fc2 = nn.Linear(in_features=160, out_features=10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "            Performs a forward pass of a batch / instance\n",
        "        \"\"\"\n",
        "        # ---- Convolution Layers ----\n",
        "        # First CNN layer\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        # Second CNN layer\n",
        "        x = self.pool(F.relu(self.conv2(x))) \n",
        "        # Third CNN layer\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        # ---- Linear Layers ----\n",
        "        # Flatten to use in Linear Layers\n",
        "        x = x.view(-1, 48*3*3)\n",
        "        # First Linear Layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Second Linear Layer. Doesn't use an activation\n",
        "        x = self.fc2(x)\n",
        "        # No softmax function is used here as loss fn handles it.\n",
        "        \n",
        "        # Return results\n",
        "        return x\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size: 32\n",
            "x0 shape is: torch.Size([32, 3, 32, 32])\n",
            "x1 shape is: torch.Size([32, 16, 30, 30])\n",
            "x2 shape is: torch.Size([32, 16, 15, 15])\n",
            "x3 shape is: torch.Size([32, 32, 15, 15])\n",
            "x4 shape is: torch.Size([32, 32, 7, 7])\n",
            "x5 shape is: torch.Size([32, 48, 7, 7])\n",
            "x6 shape is: torch.Size([32, 48, 3, 3])\n",
            "x7 shape is: torch.Size([32, 432])\n",
            "x8 shape is: torch.Size([32, 160])\n",
            "x9 shape is: torch.Size([32, 10])\n"
          ]
        }
      ],
      "source": [
        "##\n",
        "# Code Testing CNN's layer sizes are correct, mainly just to validate the model is actually built correctly.\n",
        "##\n",
        "\n",
        "test_net = BaselineNetwork()\n",
        "\n",
        "print(f\"Batch size: {len(sample_images)}\")\n",
        "\n",
        "x0 = sample_images\n",
        "print(f\"x0 shape is: {x0.shape}\")\n",
        "x1 = F.relu(test_net.conv1(x0))\n",
        "print(f\"x1 shape is: {x1.shape}\")\n",
        "x2 = test_net.pool(x1)\n",
        "print(f\"x2 shape is: {x2.shape}\")\n",
        "x3 = F.relu(test_net.conv2(x2))\n",
        "print(f\"x3 shape is: {x3.shape}\")\n",
        "x4 = test_net.pool(x3)\n",
        "print(f\"x4 shape is: {x4.shape}\")\n",
        "x5 = F.relu(test_net.conv3(x4))\n",
        "print(f\"x5 shape is: {x5.shape}\")\n",
        "x6 = test_net.pool(x5)\n",
        "print(f\"x6 shape is: {x6.shape}\")\n",
        "x7 = x6.view(-1, 48*3*3)\n",
        "print(f\"x7 shape is: {x7.shape}\")\n",
        "x8 = F.relu(test_net.fc1(x7))\n",
        "print(f\"x8 shape is: {x8.shape}\")\n",
        "x9 = F.relu(test_net.fc2(x8))\n",
        "print(f\"x9 shape is: {x9.shape}\")\n",
        "\n",
        "pred_logits = test_net.forward(sample_images)\n",
        "assert list(pred_logits.shape) == [32, 10], \"Network does not output expected logits.\"\n",
        "\n",
        "del [test_net, pred_logits, x0, x1, x2, x3, x4, x5, x6, x7, x8, x9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l4idTCtPfbc"
      },
      "source": [
        "# Results (instructions) - 55 MARKS <ignore>\n",
        "Use the Results section to summarise your findings from the experiments. For each experiment, use the Markdown/text cell to describe and explain your results, and use the code cell (and additional code cells if necessary) to conduct the experiment and produce figures to show your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batSfx6_oUOk"
      },
      "source": [
        "### Experiment 1 (17 MARKS) <ignore>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Write up results for Experiment 1 here*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BiBjSG9ioDPR"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3646559868.py, line 99)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 99\u001b[1;36m\u001b[0m\n\u001b[1;33m    epoch_accuracy =\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#############################\n",
        "### Code for Experiment 1 ###\n",
        "#############################\n",
        "\n",
        "import random \n",
        "\n",
        "##\n",
        "# Splitting training data into subsets of training and validation subsets using 80:20 ratio.\n",
        "##\n",
        "\n",
        "def exp1_create_train_val_split(seed):\n",
        "    \"\"\"\n",
        "    Creates a train/validation split of 80:20 for experiment 1. \n",
        "    Split is randomised based on a provided seed.\n",
        "\n",
        "    Arguments:\n",
        "        seed: the seed to use for the splitter\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of training dataloader and validation dataloader\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create generator from provided seed\n",
        "    generator = torch.Generator().manual_seed(seed)\n",
        "    \n",
        "    # Split larger training dataset into a training subset and validation subset.\n",
        "    train_subset, val_subset = torch.utils.data.random_split(full_train_set, [0.8, 0.2], generator)\n",
        "    \n",
        "    # Create dataloader for the training subset\n",
        "    train_sub_loader = torch.utils.data.DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "    # Create dataloader for validation subset.\n",
        "    val_sub_loader = torch.utils.data.DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "    \n",
        "    # return the two\n",
        "    return train_sub_loader, val_sub_loader\n",
        "\n",
        "\n",
        "\n",
        "def exp1_train(model, dataloader, loss_fn, optimizer, device):\n",
        "    \"\"\"Train Experiment 1's model on a single pass through the dataloader.\n",
        "\n",
        "    Args:\n",
        "        model: The model to perform the epoch on\n",
        "        dataloader: The dataloader to use.\n",
        "        loss_fn: The loss Criterion to use.\n",
        "        optimizer: the optimizer to use, this is set up with the experiment's learning rate.\n",
        "        device: The device to train on.\n",
        "    \n",
        "    Returns:\n",
        "        model: The updated model.\n",
        "        all_train_true_labels: the true training labels from all batches for this epoch.\n",
        "        all_train_predicted_labels: the predicted training labels from all batches for this epoch.\n",
        "        average_batch_loss: the average training loss over all of the batches for this epoch. \n",
        "        \n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "    # Put model into training mode\n",
        "    model.train()\n",
        "\n",
        "    # Create loss tracking variable\n",
        "    running_loss = 0\n",
        "\n",
        "    # Create prediction tracking lists\n",
        "    all_train_predicted_labels = []\n",
        "    all_train_true_labels = []\n",
        "\n",
        "\n",
        "    # For each batch in the dataloader...\n",
        "    for _, data in enumerate(dataloader,0):\n",
        "        \n",
        "        # Get model inputs, data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        \n",
        "        # Accumulate true labels from this batch into all true labels list\n",
        "        all_train_true_labels.extend(labels.tolist())\n",
        "\n",
        "        # transfer input and labels over to device.\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Perform a forward pass.\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Get predicted labels for each item in batch\n",
        "        _, batch_train_predicted_labels = torch.max(outputs, 1)\n",
        "        # Accumulate predicted labels from this batch into all predictions list\n",
        "        all_train_predicted_labels.extend(batch_train_predicted_labels.tolist())\n",
        "        \n",
        "\n",
        "\n",
        "        \n",
        "        # Get this batches loss\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        # Calculate updated gradients\n",
        "        loss.backward()\n",
        "        # Perform network Optimisation\n",
        "        optimizer.step()\n",
        "\n",
        "        # get Loss statistics and update running total\n",
        "        current_loss = loss.item()\n",
        "        running_loss += current_loss\n",
        "\n",
        "    # calculate the average batch loss over this epoch.\n",
        "    average_batch_loss = running_loss / len(dataloader)\n",
        "\n",
        "    return model, all_train_true_labels, all_train_predicted_labels, average_batch_loss\n",
        "\n",
        "\n",
        "\n",
        "def exp1_evaluate(model, dataloader, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Evaluate Experiment 1's model through one pass of the dataloader.\n",
        "\n",
        "    Args:\n",
        "        model: The model to evaluate\n",
        "        dataloader: The dataloader to evaluate the model on\n",
        "        loss_fn: The loss function to use\n",
        "        device: The device to perform the evaluation on.\n",
        "\n",
        "    Returns:\n",
        "        model: The model after evaluation\n",
        "        all_val_true_labels: All of the true labels from the batches in this epoch.\n",
        "        all_val_predicted_labels: All of the predicted labels from the batches in this epoch.\n",
        "        average_batch_loss: The average validation loss over all of the batches in the epoch.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    \n",
        "    # Put model into evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Create loss tracking variable\n",
        "    running_loss = 0\n",
        "\n",
        "    # Create prediction tracking lists\n",
        "    all_val_true_labels = []\n",
        "    all_val_predicted_labels = []\n",
        "\n",
        "\n",
        "    # don't worry about gradients during validation  \n",
        "    with torch.no_grad:\n",
        "\n",
        "        #over all batches...\n",
        "        for _, data in enumerate(dataloader, 0):\n",
        "            \n",
        "            # Get the model inputs and labels of this batch\n",
        "            inputs, labels = data\n",
        "\n",
        "            # Accumulate the true labels of this batch into the all true values list\n",
        "            all_val_true_labels.extend(labels.tolist())\n",
        "\n",
        "            # move inputs and labels over to device.\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Perform a forward pass.\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Get predicted labels for each item in batch\n",
        "            _, batch_val_predicted_labels = torch.max(outputs, 1)\n",
        "            # Accumulate predicted labels from this batch into all predictions list\n",
        "            all_val_predicted_labels.extend(batch_val_predicted_labels.tolist())\n",
        "\n",
        "            #calculate this batches loss\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            current_loss = loss.item()\n",
        "\n",
        "            running_loss += current_loss\n",
        "\n",
        "    # calculate the average loss over every batch.\n",
        "    average_batch_loss = running_loss / len(dataloader)\n",
        "\n",
        "    return model, all_val_true_labels, all_val_predicted_labels, average_batch_loss\n",
        "\n",
        "\n",
        "def do_experiment():\n",
        "    opti\n",
        "    \n",
        "# Keep using the GPT2 Task 1 colab notebook, it's so damn helpful.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Progress through 5 averaging loops: 100%|██████████| 5/5 [00:02<00:00,  1.98it/s]\n",
            "Progress through 5 averaging loops: 100%|██████████| 5/5 [00:02<00:00,  1.99it/s]\n",
            "Progress through 5 averaging loops: 100%|██████████| 5/5 [00:02<00:00,  1.99it/s]\n",
            "Progress through 5 averaging loops: 100%|██████████| 5/5 [00:02<00:00,  1.98it/s]\n",
            "Progress through 5 averaging loops: 100%|██████████| 5/5 [00:02<00:00,  1.99it/s]\n",
            "Progress through learning rates: 100%|██████████| 5/5 [00:12<00:00,  2.52s/it]\n"
          ]
        }
      ],
      "source": [
        "###\n",
        "# Main Experiment Loop.\n",
        "###\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# define learning rates to test\n",
        "learning_rates = [1e-1, 1e-2, 1e-3, 1e-4, 0]\n",
        "\n",
        "\n",
        "# iterate over each learning rate.\n",
        "for lr in tqdm(learning_rates, desc=\"Progress through learning rates\"):\n",
        "    # iterate over 5 different sets of training/validation data.\n",
        "    for test_idx in tqdm(range(5), desc=\"Progress through 5 averaging loops\"):\n",
        "        \n",
        "        # Randomise seed for each iteration\n",
        "        random_seed = random.randint(0, 1000)\n",
        "        \n",
        "        # Create dataloaders for training and validation subsets,\n",
        "        exp1_train_loader, exp1_val_loader = exp1_create_train_val_split(random_seed)\n",
        "        \n",
        "        model = BaselineNetwork()\n",
        "        \n",
        "        # Define loss criteria - using cross entropy loss as this is multi-class classificaiton problem.\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Create optimizer. Optimizer \n",
        "        optimizer = optimizer.SGD(BaselineNetwork.parameters(), lr=lr) \n",
        "\n",
        "        for i, data in enumerate(exp1_train_loader, 0):\n",
        "            \n",
        "            inputs, labels = data\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "# Scheduler Experiment Loop\n",
        "###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqW3G7sRokZt"
      },
      "source": [
        "### Experiment 2 (19 MARKS) <ignore>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Write up results for Experiment 2 here*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#############################\n",
        "### Code for Experiment 2 ###\n",
        "#############################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 3 (19 MARKS) <ignore>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Write up results for Experiment 3 here*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAaa3uOcoQ1W"
      },
      "outputs": [],
      "source": [
        "#############################\n",
        "### Code for Experiment 3 ###\n",
        "#############################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pRSqHgx0tvD"
      },
      "source": [
        "# Conclusions and Discussion (instructions) - 25 MARKS <ignore>\n",
        "In this section, you are expected to:\n",
        "* briefly summarise and describe the conclusions from your experiments (8 MARKS).\n",
        "* discuss whether or not your results are expected, providing scientific reasons (8 MARKS).\n",
        "* discuss two or more alternative/additional methods that may enhance your model, with scientific reasons (4 MARKS). \n",
        "* Reference two or more relevant academic publications that support your discussion. (4 MARKS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v02f4sbyPuLh"
      },
      "source": [
        "*Write your Conclusions/Discussion here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# References (instructions) <ignore>\n",
        "Use the cell below to add your references. A good format to use for references is like this:\n",
        "\n",
        "[AB Name], [CD Name], [EF Name] ([year]), [Article title], [Journal/Conference Name] [volume], [page numbers] or [article number] or [doi]\n",
        "\n",
        "Some examples:\n",
        "\n",
        "JEM Bennett, A Phillipides, T Nowotny (2021), Learning with reinforcement prediction errors in a model of the Drosophila mushroom body, Nat. Comms 12:2569, doi: 10.1038/s41467-021-22592-4\n",
        "\n",
        "SO Kaba, AK Mondal, Y Zhang, Y Bengio, S Ravanbakhsh (2023), Proc. 40th Int. Conf. Machine Learning, 15546-15566"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*List your references here*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
